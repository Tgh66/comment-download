import streamlit as st
import pandas as pd
from io import BytesIO
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTF
import time

# ==========================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šä½ ç°æœ‰çš„æ ¸å¿ƒé€»è¾‘ (ä¿æŒä¸å˜)
# ==========================================

# å‡è®¾è¿™æ˜¯ä½ ç°æœ‰çš„çˆ¬è™«å‡½æ•°ï¼Œä½ éœ€è¦ç¡®ä¿å®ƒè¿”å›åŒ…å« 'likes' (ç‚¹èµæ•°) çš„å­—å…¸
# å¦‚æœä½ ç°åœ¨çš„ä»£ç åªæ˜¯ print å‡ºæ¥ï¼Œè¯·ä¿®æ”¹å®ƒè®©å®ƒ return ä¸€ä¸ªå­—å…¸
def existing_scraper_function(url, cookies=None):
    """
    è¿™é‡Œä»£è¡¨ä½ ç°æœ‰çš„å¤æ‚é€»è¾‘ï¼š
    1. è¯†åˆ«æ˜¯Bç«™/æŠ–éŸ³/Youtube
    2. ä½¿ç”¨Cookieè®¤è¯
    3. è§£æè§†é¢‘ä¿¡æ¯
    """
    # æ¨¡æ‹Ÿè¿”å›çš„æ•°æ®ç»“æ„ (è¯·ç¡®ä¿ä½ çš„çˆ¬è™«æå–äº† 'likes' å­—æ®µ)
    # æ³¨æ„ï¼šç‚¹èµæ•°å¿…é¡»æ˜¯æ•°å­—ç±»å‹ (int)ï¼Œå¦‚æœæ˜¯å­—ç¬¦ä¸² '1.2ä¸‡' éœ€è¦è½¬æ¢
    
    # -------------------------------------------------
    # âš ï¸åœ¨æ­¤å¤„ä¿ç•™ä½ çš„å®é™…ä»£ç ï¼Œä¸è¦ä½¿ç”¨ä¸‹é¢çš„æ¨¡æ‹Ÿä»£ç âš ï¸
    # -------------------------------------------------
    import random
    # æ¨¡æ‹Ÿæ•°æ®ä»…ä¾›æ¼”ç¤ºæ’åºåŠŸèƒ½
    mock_data = {
        "title": f"æµ‹è¯•è§†é¢‘æ ‡é¢˜ - {url[-5:]}",
        "url": url,
        "author": "æµ‹è¯•ä½œè€…",
        "likes": random.randint(100, 100000), # å…³é”®å­—æ®µï¼šç‚¹èµæ•°
        "platform": "Bilibili" if "bilibili" in url else "Other"
    }
    time.sleep(0.5) # æ¨¡æ‹Ÿè¯·æ±‚è€—æ—¶
    return mock_data

# ==========================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šæ–°å¢çš„ PDF ç”Ÿæˆå·¥å…·å‡½æ•°
# ==========================================

def generate_pdf(dataframe):
    buffer = BytesIO()
    p = canvas.Canvas(buffer, pagesize=A4)
    width, height = A4
    y = height - 40
    
    # æ³¨æ„ï¼šReportLabé»˜è®¤ä¸æ”¯æŒä¸­æ–‡ï¼Œéœ€è¦æ³¨å†Œå­—ä½“ã€‚
    # ä¸ºäº†é˜²æ­¢æŠ¥é”™ï¼Œè¿™é‡Œç”¨é€šç”¨å¤„ç†ï¼Œå®é™…éƒ¨ç½²å»ºè®®ä¸‹è½½ 'SimHei.ttf' å¹¶æ³¨å†Œ
    # æˆ–è€…ä»…åœ¨PDFä¸­è¾“å‡ºè‹±æ–‡/æ•°å­—ï¼Œä¸­æ–‡å¯èƒ½æ˜¾ç¤ºä¹±ç 
    p.setFont("Helvetica", 10) 
    
    p.drawString(30, y, "Video Export List")
    y -= 20
    
    for index, row in dataframe.iterrows():
        if y < 40: # æ¢é¡µå¤„ç†
            p.showPage()
            p.setFont("Helvetica", 10)
            y = height - 40
            
        # ç®€å•å†™å…¥ æ ‡é¢˜ (æˆªæ–­ä»¥é˜²è¿‡é•¿) å’Œ ç‚¹èµæ•°
        # å®é™…é¡¹ç›®ä¸­å»ºè®®å¤„ç†ä¸­æ–‡å­—ä½“
        title_text = str(row['title'])[:40] 
        text = f"Title: {title_text}... | Likes: {row['likes']} | URL: {row['url']}"
        p.drawString(30, y, text)
        y -= 20
        
    p.save()
    buffer.seek(0)
    return buffer

# ==========================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šStreamlit ä¸»ç•Œé¢é€»è¾‘ (ä¿®æ”¹éƒ¨åˆ†)
# ==========================================

st.title("å¤šå¹³å°è§†é¢‘æŠ“å–å·¥å…· (å«æ’åºå¯¼å‡º)")

# è¾“å…¥åŒºåŸŸ
urls_input = st.text_area("è¯·è¾“å…¥è§†é¢‘é“¾æ¥ (ä¸€è¡Œä¸€ä¸ª):")
run_button = st.button("å¼€å§‹æŠ“å–")

# åˆå§‹åŒ– session_state ç”¨äºå­˜å‚¨æŠ“å–ç»“æœï¼Œé˜²æ­¢æ’åºæ—¶é‡åˆ·æ¶ˆå¤±
if 'scraped_data' not in st.session_state:
    st.session_state.scraped_data = []

if run_button and urls_input:
    url_list = urls_input.split('\n')
    results = []
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # 1. æ‰§è¡ŒæŠ“å–
    for i, url in enumerate(url_list):
        if url.strip():
            status_text.text(f"æ­£åœ¨åˆ†æ: {url}")
            try:
                # è°ƒç”¨ä½ ç°æœ‰çš„é€»è¾‘
                data = existing_scraper_function(url.strip())
                if data:
                    results.append(data)
            except Exception as e:
                st.error(f"é“¾æ¥ {url} è§£æå¤±è´¥: {e}")
        progress_bar.progress((i + 1) / len(url_list))
    
    # å­˜å…¥ Session State
    st.session_state.scraped_data = results
    status_text.text("åˆ†æå®Œæˆï¼")

# 2. ç»“æœå±•ç¤ºä¸å¤„ç†åŒºåŸŸ
if st.session_state.scraped_data:
    st.divider()
    st.subheader("ğŸ“Š ç»“æœåˆ†æ")
    
    # å°†åˆ—è¡¨è½¬æ¢ä¸º Pandas DataFrame
    df = pd.DataFrame(st.session_state.scraped_data)
    
    # --- æ–°å¢åŠŸèƒ½ï¼šæ’åºæ§åˆ¶ ---
    col1, col2 = st.columns([1, 3])
    with col1:
        sort_method = st.radio(
            "æŒ‰ç…§ç‚¹èµæ•°æ’åº:",
            ("é™åº (ä»é«˜åˆ°ä½)", "å‡åº (ä»ä½åˆ°é«˜)")
        )
    
    # æ‰§è¡Œæ’åºé€»è¾‘
    ascending_bool = True if "å‡åº" in sort_method else False
    if 'likes' in df.columns:
        df = df.sort_values(by='likes', ascending=ascending_bool)
        # é‡ç½®ç´¢å¼•ï¼Œè®©åºå·ä»1å¼€å§‹
        df = df.reset_index(drop=True)
    else:
        st.warning("æœªæ£€æµ‹åˆ°'likes'å­—æ®µï¼Œæ— æ³•æ’åºã€‚è¯·æ£€æŸ¥çˆ¬è™«è¿”å›å€¼ã€‚")

    # æ˜¾ç¤ºè¡¨æ ¼
    st.dataframe(
        df, 
        column_config={
            "url": st.column_config.LinkColumn("è§†é¢‘é“¾æ¥"),
            "likes": st.column_config.NumberColumn("ç‚¹èµæ•°", format="%d")
        },
        use_container_width=True
    )

    # --- æ–°å¢åŠŸèƒ½ï¼šå¯¼å‡ºä¸‹è½½ ---
    st.subheader("ğŸ’¾ æ•°æ®å¯¼å‡º")
    d_col1, d_col2 = st.columns(2)
    
    # å¯¼å‡º CSV
    csv_data = df.to_csv(index=False).encode('utf-8-sig') # utf-8-sig è§£å†³Excelä¸­æ–‡ä¹±ç 
    with d_col1:
        st.download_button(
            label="ä¸‹è½½ CSV è¡¨æ ¼",
            data=csv_data,
            file_name='video_stats.csv',
            mime='text/csv',
        )
        
    # å¯¼å‡º PDF
    with d_col2:
        pdf_data = generate_pdf(df)
        st.download_button(
            label="ä¸‹è½½ PDF æŠ¥å‘Š",
            data=pdf_data,
            file_name='video_stats.pdf',
            mime='application/pdf',
        )
