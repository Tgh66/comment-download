import streamlit as st
import asyncio
import pandas as pd
import re
import time
import requests
import json
import urllib.parse
import io 
import os
from bilibili_api import video, comment, Credential
from bilibili_api.exceptions import ResponseCodeException

# --- PDF ç”Ÿæˆç›¸å…³åº“ ---
from reportlab.lib.pagesizes import A4
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.cidfonts import UnicodeCIDFont 
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib import colors

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="Bç«™è¯„è®ºæŠ“å–ç¥å™¨ (å®Œç¾PDFç‰ˆ)", page_icon="ğŸª", layout="wide")

# --- åˆå§‹åŒ– Session State ---
if 'comments_data' not in st.session_state:
    st.session_state.comments_data = None
if 'video_title' not in st.session_state:
    st.session_state.video_title = ""
if 'bv_id' not in st.session_state:
    st.session_state.bv_id = ""

# --- è¾…åŠ©å‡½æ•° ---

def get_real_url(url):
    """å¤„ç† b23.tv çŸ­é“¾æ¥"""
    if "b23.tv" in url:
        try:
            headers = {"User-Agent": "Mozilla/5.0"}
            resp = requests.get(url, headers=headers, allow_redirects=True, timeout=10)
            return resp.url
        except:
            return url
    return url

def extract_bv(url):
    """æå–BVå·"""
    real_url = get_real_url(url)
    pattern = r"(BV[a-zA-Z0-9]{10})"
    match = re.search(pattern, real_url)
    if match:
        return match.group(1), real_url
    return None, real_url

def parse_cookie_json(json_str):
    """è§£æç”¨æˆ·ç²˜è´´çš„ JSON Cookie æ•°æ®"""
    try:
        data = json.loads(json_str)
        
        cookie_list = []
        if isinstance(data, list):
            cookie_list = data
        elif isinstance(data, dict) and "cookies" in data:
            cookie_list = data["cookies"]
        else:
            return None, "JSON æ ¼å¼ä¸æ­£ç¡®ï¼Œæœªæ‰¾åˆ° cookies åˆ—è¡¨"

        cookies = {c['name']: c['value'] for c in cookie_list}
        
        sessdata = cookies.get('SESSDATA')
        bili_jct = cookies.get('bili_jct')
        buvid3 = cookies.get('buvid3')

        if not sessdata or not bili_jct:
            return None, "Cookie ä¸­ç¼ºå°‘ SESSDATA æˆ– bili_jct"

        sessdata = urllib.parse.unquote(sessdata)
        bili_jct = urllib.parse.unquote(bili_jct)

        cred = Credential(sessdata=sessdata, bili_jct=bili_jct, buvid3=buvid3)
        return cred, None

    except json.JSONDecodeError:
        return None, "JSON è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥å¤åˆ¶æ˜¯å¦å®Œæ•´"
    except Exception as e:
        return None, f"Cookie è§£æé”™è¯¯: {str(e)}"

# --- PDF ç”Ÿæˆå‡½æ•° (è‡ªåŠ¨æ¢è¡Œ + å®Œæ•´æ˜¾ç¤ºç‰ˆ) ---
def create_pdf(dataframe, title):
    """
    å°† DataFrame è½¬æ¢ä¸º PDF å­—èŠ‚æµ (æ”¯æŒè‡ªåŠ¨æ¢è¡Œ)
    """
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4)
    elements = []

    # 1. æ³¨å†Œ CID ä¸­æ–‡å­—ä½“
    font_name = 'STSong-Light'
    try:
        pdfmetrics.registerFont(UnicodeCIDFont('STSong-Light'))
    except Exception as e:
        font_name = "Helvetica"

    # 2. å®šä¹‰æ ·å¼
    styles = getSampleStyleSheet()
    
    # æ ‡é¢˜æ ·å¼
    title_style = styles['Title']
    if font_name == 'STSong-Light':
        title_style.fontName = font_name
    
    # æ­£æ–‡å†…å®¹æ ·å¼ (ç”¨äºè¡¨æ ¼å†…çš„é•¿æ–‡æœ¬è‡ªåŠ¨æ¢è¡Œ)
    # leading æ˜¯è¡Œé—´è·ï¼ŒfontSize æ˜¯å­—å·
    cell_style = ParagraphStyle(
        name='CellStyle',
        fontName=font_name,
        fontSize=9,
        leading=12,
        wordWrap='CJK' # æ”¯æŒä¸­æ–‡æ–­è¡Œ
    )

    safe_title = re.sub(r'[^\w\s\u4e00-\u9fa5]', '', title)
    elements.append(Paragraph(f"è§†é¢‘è¯„è®º: {safe_title}", title_style))
    elements.append(Paragraph("<br/><br/>", styles['Normal']))

    # 3. å‡†å¤‡è¡¨æ ¼æ•°æ®
    # å®šä¹‰åˆ—å®½ (å•ä½: point, A4 å®½åº¦çº¦ä¸º 595, å»æ‰é¡µè¾¹è·å¯ç”¨çº¦ 450-500)
    # åˆ—é¡ºåº: ç”¨æˆ·å, å†…å®¹, ç‚¹èµ, æ—¶é—´, å›å¤æ•°
    col_widths = [70, 240, 40, 80, 40] 

    # å¤„ç†è¡¨å¤´
    headers = dataframe.columns.to_list()
    processed_data = [headers]

    # å¤„ç†æ¯ä¸€è¡Œæ•°æ®
    for index, row in dataframe.iterrows():
        new_row = []
        
        # æå–æ¯ä¸€åˆ—çš„æ•°æ®
        uname = str(row['ç”¨æˆ·å'])
        content = str(row['å†…å®¹'])
        like = str(row['ç‚¹èµ'])
        time_str = str(row['æ—¶é—´'])
        reply_count = str(row['å›å¤æ•°'])

        # æ¸…ç† PDF ä¸æ”¯æŒçš„å­—ç¬¦
        content = re.sub(r'[^\x00-\x7F\u4e00-\u9fa5]+', '', content)
        uname = re.sub(r'[^\x00-\x7F\u4e00-\u9fa5]+', '', uname)

        # ã€æ ¸å¿ƒé€»è¾‘ã€‘å°†é•¿æ–‡æœ¬è½¬æ¢ä¸º Paragraph å¯¹è±¡ï¼Œå®ç°è‡ªåŠ¨æ¢è¡Œ
        # å…¶ä»–çŸ­å­—æ®µå¯ä»¥ç›´æ¥ç”¨å­—ç¬¦ä¸²ï¼Œæˆ–è€…ä¹Ÿè½¬ä¸º Paragraph ä»¥ä¿æŒæ ¼å¼ç»Ÿä¸€
        # è¿™é‡Œæˆ‘ä»¬å°† å†…å®¹(ç´¢å¼•1) è®¾ä¸º Paragraph
        new_row.append(Paragraph(uname, cell_style)) # ç”¨æˆ·åä¹Ÿå¯èƒ½é•¿ï¼ŒåŠ ä¸Šä¿é™©
        new_row.append(Paragraph(content, cell_style)) # å†…å®¹å¿…é¡»æ¢è¡Œ
        new_row.append(like)
        new_row.append(time_str) # æ—¶é—´é€šå¸¸å›ºå®šå®½åº¦
        new_row.append(reply_count)

        processed_data.append(new_row)

    # 4. åˆ›å»ºè¡¨æ ¼å¯¹è±¡ï¼Œä¼ å…¥åˆ—å®½å‚æ•°
    t = Table(processed_data, colWidths=col_widths)
    
    # 5. è®¾ç½®è¡¨æ ¼æ ·å¼
    style = TableStyle([
        ('FONTNAME', (0, 0), (-1, -1), font_name), 
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey), # è¡¨å¤´èƒŒæ™¯
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke), # è¡¨å¤´æ–‡å­—é¢œè‰²
        ('ALIGN', (0, 0), (-1, 0), 'CENTER'), # è¡¨å¤´å±…ä¸­
        ('VALIGN', (0, 0), (-1, -1), 'TOP'), # æ‰€æœ‰å•å…ƒæ ¼å†…å®¹é¡¶å¯¹é½ (å¯¹é•¿æ–‡å¾ˆé‡è¦)
        ('FONTSIZE', (0, 0), (-1, 0), 10),
        ('FONTSIZE', (0, 0), (-1, -1), 9),
        ('GRID', (0, 0), (-1, -1), 0.5, colors.black), # è¡¨æ ¼çº¿
        ('LEFTPADDING', (0, 0), (-1, -1), 4),
        ('RIGHTPADDING', (0, 0), (-1, -1), 4),
        ('TOPPADDING', (0, 0), (-1, -1), 4),
        ('BOTTOMPADDING', (0, 0), (-1, -1), 4),
    ])
    t.setStyle(style)
    elements.append(t)

    # 6. ç”Ÿæˆ PDF
    try:
        doc.build(elements)
        buffer.seek(0)
        return buffer
    except Exception as e:
        print(f"PDFç”Ÿæˆé”™è¯¯: {e}")
        return None

# ğŸ‘‡ è‡ªå®šä¹‰ç±»
class VideoTypeFix:
    value = 1 

async def fetch_comments_async(bv_id, limit_pages, credential=None):
    """
    å¼‚æ­¥æŠ“å–è¯„è®º
    """
    v = video.Video(bvid=bv_id, credential=credential)
    
    try:
        info = await v.get_info()
        oid = info['aid']
        title = info['title']
    except Exception as e:
        return None, f"æ— æ³•è·å–è§†é¢‘ä¿¡æ¯: {str(e)}"

    comments_data = []
    page = 1
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        while page <= limit_pages:
            status_text.text(f"ğŸš€ æ­£åœ¨æŠ“å–ç¬¬ {page}/{limit_pages} é¡µ...")
            
            try:
                c = await comment.get_comments(oid, VideoTypeFix(), page, credential=credential)
            except ResponseCodeException as e:
                if e.code == -404: break
                st.warning(f"API é”™è¯¯ä»£ç : {e.code}")
                break
            except Exception as e:
                st.warning(f"æœªçŸ¥é”™è¯¯: {e}")
                break

            if 'replies' not in c or not c['replies']:
                status_text.text("âœ… å·²åˆ°è¾¾åº•éƒ¨")
                break
            
            for r in c['replies']:
                item = {
                    'ç”¨æˆ·å': r['member']['uname'],
                    'å†…å®¹': r['content']['message'],
                    'ç‚¹èµ': int(r['like']), 
                    'æ—¶é—´': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(r['ctime'])),
                    'å›å¤æ•°': int(r['count'])
                }
                comments_data.append(item)
                
                if r.get('replies'):
                    for sub in r['replies']:
                        sub_item = {
                            'ç”¨æˆ·å': sub['member']['uname'],
                            'å†…å®¹': f"[å›å¤] {sub['content']['message']}",
                            'ç‚¹èµ': int(sub['like']),
                            'æ—¶é—´': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(sub['ctime'])),
                            'å›å¤æ•°': 0
                        }
                        comments_data.append(sub_item)

            progress_bar.progress(min(page / limit_pages, 1.0))
            page += 1
            await asyncio.sleep(0.5)
            
    except Exception as e:
        st.error(f"ä¸­æ–­: {e}")
    
    return title, comments_data

# --- UI å¸ƒå±€ ---

st.title("ğŸª Bç«™è¯„è®ºæŠ“å– (å®Œç¾PDFç‰ˆ)")

with st.sidebar:
    st.header("ğŸ” èº«ä»½éªŒè¯ (æ¨è)")
    st.info("ç²˜è´´ Cookie JSON")
    
    cookie_input = st.text_area(
        "Cookie æ•°æ®:", 
        height=150,
        placeholder='{"url": "...", "cookies": [...]}'
    )
    
    cred = None
    if cookie_input:
        cred, err_msg = parse_cookie_json(cookie_input)
        if cred:
            st.success("âœ… Cookie è§£ææˆåŠŸï¼")
        else:
            st.error(f"âŒ {err_msg}")
            
    st.divider()
    max_pages = st.slider("æŠ“å–é¡µæ•°", 1, 100, 5)

url_input = st.text_input("ğŸ‘‡ è§†é¢‘é“¾æ¥", placeholder="https://b23.tv/...")

# === æŠ“å– ===
if st.button("å¼€å§‹æŠ“å–", type="primary"):
    if not url_input:
        st.warning("è¯·è¾“å…¥é“¾æ¥")
    else:
        bv_id, real_url = extract_bv(url_input)
        if not bv_id:
            st.error("æ— æ³•è¯†åˆ« BV å·")
        else:
            st.success(f"æ­£åœ¨æŠ“å–: {bv_id}")
            try:
                loop = asyncio.get_event_loop()
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            
            title, data = loop.run_until_complete(fetch_comments_async(bv_id, max_pages, credential=cred))
            
            if isinstance(data, str):
                st.error(data)
            elif data:
                st.session_state.comments_data = data
                st.session_state.video_title = title
                st.session_state.bv_id = bv_id
                st.rerun()
            else:
                st.warning("æœªæŠ“å–åˆ°æ•°æ®ã€‚")

# === æ˜¾ç¤º ===
if st.session_state.comments_data:
    st.divider()
    
    title = st.session_state.video_title
    bv_id = st.session_state.bv_id
    data = st.session_state.comments_data
    
    st.subheader(f"ğŸ“„ {title}")
    
    df = pd.DataFrame(data)
    
    col1, col2 = st.columns([3, 1])
    
    with col2:
        st.markdown("### ğŸ› ï¸ æ•°æ®é€‰é¡¹")
        
        sort_order = st.radio(
            "æ’åºæ–¹å¼ (æŒ‰ç‚¹èµ)",
            ("é»˜è®¤ (æ—¶é—´)", "ç‚¹èµæ•° (é«˜åˆ°ä½)", "ç‚¹èµæ•° (ä½åˆ°é«˜)")
        )
        
        if sort_order == "ç‚¹èµæ•° (é«˜åˆ°ä½)":
            df = df.sort_values(by="ç‚¹èµ", ascending=False)
        elif sort_order == "ç‚¹èµæ•° (ä½åˆ°é«˜)":
            df = df.sort_values(by="ç‚¹èµ", ascending=True)
        
        st.write(f"å…±æŠ“å– {len(df)} æ¡è¯„è®º")
        
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ CSV",
            data=csv,
            file_name=f"{bv_id}_comments.csv",
            mime="text/csv"
        )
        
        st.write("---")
        if st.button("ç”Ÿæˆ PDF"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆ PDF (æ”¯æŒé•¿æ–‡æ¢è¡Œ)..."):
                pdf_buffer = create_pdf(df, title)
                if pdf_buffer:
                    st.success("ç”ŸæˆæˆåŠŸï¼")
                    st.download_button(
                        label="ğŸ“¥ ç‚¹å‡»ä¸‹è½½ PDF",
                        data=pdf_buffer,
                        file_name=f"{bv_id}_comments.pdf",
                        mime="application/pdf"
                    )
                else:
                    st.error("PDF ç”Ÿæˆå¤±è´¥ã€‚")

    with col1:
        st.dataframe(df, use_container_width=True, height=500)
        
    if st.button("ğŸ”„ æ¸…ç©ºç»“æœ"):
        st.session_state.comments_data = None
        st.rerun()
