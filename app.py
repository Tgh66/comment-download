import streamlit as st
import asyncio
import pandas as pd
import re
import time
import requests
from bilibili_api import video, comment
from bilibili_api.exception import ResponseCodeException

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="Bç«™è¯„è®ºæŠ“å–ç¥å™¨", page_icon="ğŸ“", layout="centered")

# --- æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

def get_real_url(url):
    """
    å¤„ç† b23.tv çŸ­é“¾æ¥ï¼Œè·å–çœŸå®é‡å®šå‘åçš„ URL
    """
    if "b23.tv" in url:
        try:
            # æ¨¡æ‹Ÿæµè§ˆå™¨è¯·æ±‚ï¼Œå…è®¸é‡å®šå‘
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            }
            resp = requests.get(url, headers=headers, allow_redirects=True, timeout=10)
            return resp.url
        except Exception as e:
            st.error(f"çŸ­é“¾æ¥è§£æå¤±è´¥: {e}")
            return url
    return url

def extract_bv(url):
    """
    ä»ä»»æ„å­—ç¬¦ä¸²ä¸­æå– BV å·
    """
    # 1. å…ˆå°è¯•è§£æçŸ­é“¾
    real_url = get_real_url(url)
    
    # 2. æ­£åˆ™æå– BV å· (å¿½ç•¥é—®å·åé¢çš„å‚æ•°)
    pattern = r"(BV[a-zA-Z0-9]{10})"
    match = re.search(pattern, real_url)
    
    if match:
        return match.group(1), real_url
    return None, real_url

async def fetch_comments_async(bv_id, limit_pages=5):
    """
    å¼‚æ­¥è·å–è¯„è®ºæ•°æ®
    """
    # åˆå§‹åŒ–
    v = video.Video(bvid=bv_id)
    
    try:
        # è·å–è§†é¢‘åŸºç¡€ä¿¡æ¯ (ä¸ºäº†æ‹¿åˆ° oid/aid)
        info = await v.get_info()
        oid = info['aid']
        title = info['title']
    except Exception as e:
        return None, f"æ— æ³•è·å–è§†é¢‘ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥BVå·æ˜¯å¦æœ‰æ•ˆã€‚é”™è¯¯: {e}"

    comments_data = []
    page = 1
    
    # UI è¿›åº¦æ¡
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        while page <= limit_pages:
            status_text.text(f"ğŸš€ æ­£åœ¨æŠ“å–ç¬¬ {page}/{limit_pages} é¡µ...")
            
            try:
                # è·å–è¯„è®º (type_=1 ä»£è¡¨è§†é¢‘)
                c = await comment.get_comments(oid, comment.ResourceType.VIDEO, page)
            except ResponseCodeException as e:
                # æŸäº›è§†é¢‘è¯„è®ºåŒºå…³é—­æˆ–éœ€è¦ç™»å½•
                if e.code == -404: 
                    break 
                else:
                    raise e

            # æ£€æŸ¥æ˜¯å¦æœ‰è¯„è®ºå†…å®¹
            if 'replies' not in c or not c['replies']:
                status_text.text("âœ… å·²åˆ°è¾¾è¯„è®ºåŒºåº•éƒ¨ã€‚")
                break
            
            for r in c['replies']:
                # è§£æä¸»è¯„è®º
                item = {
                    'ç±»å‹': 'ä¸»è¯„è®º',
                    'ç”¨æˆ·å': r['member']['uname'],
                    'å†…å®¹': r['content']['message'],
                    'ç‚¹èµ': r['like'],
                    'æ—¶é—´': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(r['ctime'])),
                    'æ¥¼å±‚': r.get('floor', 0)
                }
                comments_data.append(item)
                
                # è§£ææ¥¼ä¸­æ¥¼ (Bç«™APIé€šå¸¸åªè¿”å›å‰å‡ æ¡çƒ­è¯„å›å¤)
                if r.get('replies'):
                    for sub in r['replies']:
                        sub_item = {
                            'ç±»å‹': 'â””â”€ å›å¤',
                            'ç”¨æˆ·å': sub['member']['uname'],
                            'å†…å®¹': sub['content']['message'],
                            'ç‚¹èµ': sub['like'],
                            'æ—¶é—´': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(sub['ctime'])),
                            'æ¥¼å±‚': sub.get('floor', 0)
                        }
                        comments_data.append(sub_item)

            # æ›´æ–°è¿›åº¦
            progress_bar.progress(min(page / limit_pages, 1.0))
            page += 1
            
            # ä¼‘çœ é˜²æ­¢è§¦å‘é£æ§ (é‡è¦ï¼)
            await asyncio.sleep(0.8)
            
    except Exception as e:
        st.warning(f"æŠ“å–è¿‡ç¨‹ä¸­æ­¢: {str(e)}")
    
    progress_bar.progress(100)
    status_text.text("ğŸ‰ æŠ“å–å®Œæˆï¼")
    
    return title, comments_data

# --- Streamlit UI ç•Œé¢ ---

st.title("ğŸ“º Bilibili è¯„è®ºåŒºä¸€é”®å¯¼å‡º")
st.markdown("""
åˆ©ç”¨å¼€æºåº“ `bilibili-api-python` åˆ¶ä½œã€‚
æ”¯æŒæ ¼å¼ï¼š
- **æ ‡å‡†é“¾æ¥**: `https://www.bilibili.com/video/BV15RW2zvENr/...`
- **çŸ­é“¾æ¥**: `https://b23.tv/YTfd2CY`
""")

with st.sidebar:
    st.header("âš™ï¸ å‚æ•°è®¾ç½®")
    max_pages = st.number_input("æŠ“å–é¡µæ•° (æ¯é¡µçº¦20æ¡ä¸»è¯„)", min_value=1, max_value=100, value=5)
    st.info("æç¤ºï¼šä¸ç™»å½•çŠ¶æ€ä¸‹ï¼ŒBç«™APIé€šå¸¸é™åˆ¶æŸ¥çœ‹å‰å‡ é¡µæˆ–çƒ­é—¨è¯„è®ºã€‚")

# è¾“å…¥æ¡†
url_input = st.text_input("ğŸ‘‡ è¯·ç²˜è´´è§†é¢‘é“¾æ¥", placeholder="https://b23.tv/...")

if st.button("å¼€å§‹æŠ“å–", type="primary"):
    if not url_input:
        st.error("è¯·å…ˆè¾“å…¥é“¾æ¥ï¼")
    else:
        # 1. è§£æé“¾æ¥
        with st.spinner("æ­£åœ¨è§£æé“¾æ¥..."):
            bv_id, real_url = extract_bv(url_input)
        
        if not bv_id:
            st.error("âŒ æœªèƒ½è¯†åˆ«å‡º BV å·ï¼Œè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æ­£ç¡®ã€‚")
        else:
            st.success(f"âœ… è¯†åˆ«æˆåŠŸ: {bv_id}")
            st.caption(f"è§£æååœ°å€: {real_url}")
            
            # 2. è¿è¡Œå¼‚æ­¥æŠ“å–
            # åœ¨ Streamlit ä¸­è¿è¡Œ asyncio éœ€è¦æ–°å»ºå¾ªç¯æˆ–ä½¿ç”¨ asyncio.run
            try:
                title, data = asyncio.run(fetch_comments_async(bv_id, max_pages))
                
                if isinstance(data, str): # å¦‚æœè¿”å›çš„æ˜¯é”™è¯¯ä¿¡æ¯
                    st.error(data)
                elif data:
                    # 3. å±•ç¤ºç»“æœ
                    st.divider()
                    st.subheader(f"ğŸ“„ è§†é¢‘æ ‡é¢˜ï¼š{title}")
                    
                    df = pd.DataFrame(data)
                    st.dataframe(df, use_container_width=True, height=400)
                    
                    st.success(f"å…±æŠ“å– {len(df)} æ¡è¯„è®º")
                    
                    # 4. ä¸‹è½½æŒ‰é’®
                    csv = df.to_csv(index=False).encode('utf-8-sig')
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½ CSV è¡¨æ ¼",
                        data=csv,
                        file_name=f"Bç«™è¯„è®º_{bv_id}.csv",
                        mime="text/csv"
                    )
                else:
                    st.warning("ç»“æœä¸ºç©ºï¼Œå¯èƒ½æ˜¯è§†é¢‘æ²¡æœ‰è¯„è®ºæˆ–APIè®¿é—®å—é™ã€‚")
                    
            except Exception as e:
                st.error(f"è¿è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {e}")
