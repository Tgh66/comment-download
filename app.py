import streamlit as st
import asyncio
import pandas as pd
import re
import time
import requests
import json
import urllib.parse
import io 
import os
from bilibili_api import video, comment, Credential
from bilibili_api.exceptions import ResponseCodeException

# --- PDF ç”Ÿæˆç›¸å…³åº“ ---
from reportlab.lib.pagesizes import A4
from reportlab.pdfbase import pdfmetrics
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib import colors

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="Bç«™è¯„è®ºæŠ“å–ç¥å™¨ (æ’åº+PDFç‰ˆ)", page_icon="ğŸª", layout="wide")

# --- åˆå§‹åŒ– Session State (ç”¨äºæŒä¹…åŒ–ä¿å­˜æ•°æ®) ---
if 'comments_data' not in st.session_state:
    st.session_state.comments_data = None
if 'video_title' not in st.session_state:
    st.session_state.video_title = ""
if 'bv_id' not in st.session_state:
    st.session_state.bv_id = ""

# --- è¾…åŠ©å‡½æ•° ---

def get_real_url(url):
    """å¤„ç† b23.tv çŸ­é“¾æ¥"""
    if "b23.tv" in url:
        try:
            headers = {"User-Agent": "Mozilla/5.0"}
            resp = requests.get(url, headers=headers, allow_redirects=True, timeout=10)
            return resp.url
        except:
            return url
    return url

def extract_bv(url):
    """æå–BVå·"""
    real_url = get_real_url(url)
    pattern = r"(BV[a-zA-Z0-9]{10})"
    match = re.search(pattern, real_url)
    if match:
        return match.group(1), real_url
    return None, real_url

def parse_cookie_json(json_str):
    """è§£æç”¨æˆ·ç²˜è´´çš„ JSON Cookie æ•°æ®"""
    try:
        data = json.loads(json_str)
        
        cookie_list = []
        if isinstance(data, list):
            cookie_list = data
        elif isinstance(data, dict) and "cookies" in data:
            cookie_list = data["cookies"]
        else:
            return None, "JSON æ ¼å¼ä¸æ­£ç¡®ï¼Œæœªæ‰¾åˆ° cookies åˆ—è¡¨"

        cookies = {c['name']: c['value'] for c in cookie_list}
        
        sessdata = cookies.get('SESSDATA')
        bili_jct = cookies.get('bili_jct')
        buvid3 = cookies.get('buvid3')

        if not sessdata or not bili_jct:
            return None, "Cookie ä¸­ç¼ºå°‘ SESSDATA æˆ– bili_jct"

        sessdata = urllib.parse.unquote(sessdata)
        bili_jct = urllib.parse.unquote(bili_jct)

        cred = Credential(sessdata=sessdata, bili_jct=bili_jct, buvid3=buvid3)
        return cred, None

    except json.JSONDecodeError:
        return None, "JSON è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥å¤åˆ¶æ˜¯å¦å®Œæ•´"
    except Exception as e:
        return None, f"Cookie è§£æé”™è¯¯: {str(e)}"

# --- PDF ç”Ÿæˆå‡½æ•° (ä¿®å¤å­—ä½“è·¯å¾„ç‰ˆ) ---
def create_pdf(dataframe, title):
    """
    å°† DataFrame è½¬æ¢ä¸º PDF å­—èŠ‚æµ
    """
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4)
    elements = []

    # 1. æ³¨å†Œå­—ä½“ (æ ¸å¿ƒä¿®æ”¹ï¼šä¼˜å…ˆè¯»å–é¡¹ç›®ç›®å½•ä¸‹çš„å­—ä½“æ–‡ä»¶)
    font_name = "Helvetica" # é»˜è®¤è‹±æ–‡ä½œä¸ºä¿åº•
    
    # ä½ çš„å­—ä½“æ–‡ä»¶åï¼Œå¿…é¡»å’Œä½ ä¸Šä¼ åˆ° GitHub çš„æ–‡ä»¶åå®Œå…¨ä¸€è‡´ï¼
    font_file = "SimHei.ttf" 
    
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨çš„ç»å¯¹è·¯å¾„ï¼Œç¡®ä¿åœ¨äº‘ç«¯ä¹Ÿèƒ½æ‰¾åˆ°æ–‡ä»¶
    current_dir = os.path.dirname(os.path.abspath(__file__))
    font_path = os.path.join(current_dir, font_file)

    if os.path.exists(font_path):
        try:
            # æ³¨å†Œé¡¹ç›®æ–‡ä»¶å¤¹é‡Œçš„å­—ä½“
            pdfmetrics.registerFont(TTF('SimHei', font_path))
            font_name = 'SimHei'
        except Exception as e:
            print(f"å­—ä½“æ³¨å†Œå¤±è´¥: {e}")
    else:
        # å¦‚æœæ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œå°è¯•ç³»ç»Ÿçš„ï¼ˆæœ¬åœ°è°ƒè¯•ç”¨ï¼‰
        try:
            pdfmetrics.registerFont(TTF('SimHei', 'simhei.ttf')) # Windows é»˜è®¤è·¯å¾„å°è¯•
            font_name = 'SimHei'
        except:
            pass

    # 2. å‡†å¤‡æ ‡é¢˜
    styles = getSampleStyleSheet()
    title_style = styles['Title']
    # å¦‚æœåŠ è½½äº†ä¸­æ–‡ä½“ï¼Œåº”ç”¨åˆ°æ ‡é¢˜
    if font_name == 'SimHei':
        title_style.fontName = font_name
    
    safe_title = re.sub(r'[^\w\s\u4e00-\u9fa5]', '', title)
    elements.append(Paragraph(f"è§†é¢‘è¯„è®º: {safe_title}", title_style))
    elements.append(Paragraph("<br/><br/>", styles['Normal']))

    # 3. å‡†å¤‡è¡¨æ ¼æ•°æ®
    data = [dataframe.columns.to_list()] + dataframe.values.tolist()

    processed_data = []
    for row in data:
        new_row = []
        for item in row:
            str_item = str(item)
            if len(str_item) > 50:
                str_item = str_item[:50] + "..."
            # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
            str_item = re.sub(r'[^\x00-\x7F\u4e00-\u9fa5]+', '', str_item) 
            new_row.append(str_item)
        processed_data.append(new_row)

    # 4. åˆ›å»ºè¡¨æ ¼å¯¹è±¡
    t = Table(processed_data)
    
    # 5. è®¾ç½®è¡¨æ ¼æ ·å¼
    style = TableStyle([
        ('FONTNAME', (0, 0), (-1, -1), font_name), # å…¨å±€åº”ç”¨è¯¥å­—ä½“
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTSIZE', (0, 0), (-1, 0), 10),
        ('FONTSIZE', (0, 0), (-1, -1), 8),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('GRID', (0, 0), (-1, -1), 1, colors.black),
    ])
    t.setStyle(style)
    elements.append(t)

    # 6. ç”Ÿæˆ PDF
    try:
        doc.build(elements)
        buffer.seek(0)
        return buffer
    except Exception as e:
        print(f"PDFç”Ÿæˆé”™è¯¯: {e}")
        return None

# ğŸ‘‡ ã€æ ¸å¿ƒä¿®å¤ã€‘å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰ç±»ï¼Œå®Œç¾éª—è¿‡åº“çš„æ£€æŸ¥
class VideoTypeFix:
    value = 1  # è§†é¢‘ç±»å‹ ID ä¸º 1

async def fetch_comments_async(bv_id, limit_pages, credential=None):
    """
    å¼‚æ­¥æŠ“å–è¯„è®º
    """
    v = video.Video(bvid=bv_id, credential=credential)
    
    try:
        info = await v.get_info()
        oid = info['aid']
        title = info['title']
    except Exception as e:
        return None, f"æ— æ³•è·å–è§†é¢‘ä¿¡æ¯: {str(e)}"

    comments_data = []
    page = 1
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        while page <= limit_pages:
            status_text.text(f"ğŸš€ æ­£åœ¨æŠ“å–ç¬¬ {page}/{limit_pages} é¡µ...")
            
            try:
                # ğŸ‘‡ ã€å…³é”®ä¿®æ”¹ã€‘ä½¿ç”¨è‡ªå®šä¹‰å¯¹è±¡ VideoTypeFix() ä»£æ›¿æ•°å­— 1
                c = await comment.get_comments(oid, VideoTypeFix(), page, credential=credential)
            except ResponseCodeException as e:
                if e.code == -404: break
                st.warning(f"API é”™è¯¯ä»£ç : {e.code}")
                break
            except Exception as e:
                st.warning(f"æœªçŸ¥é”™è¯¯: {e}")
                break

            if 'replies' not in c or not c['replies']:
                status_text.text("âœ… å·²åˆ°è¾¾åº•éƒ¨")
                break
            
            for r in c['replies']:
                item = {
                    'ç”¨æˆ·å': r['member']['uname'],
                    'å†…å®¹': r['content']['message'],
                    'ç‚¹èµ': int(r['like']), # ç¡®ä¿è½¬æ¢ä¸ºæ•°å­—ï¼Œæ–¹ä¾¿æ’åº
                    'æ—¶é—´': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(r['ctime'])),
                    'å›å¤æ•°': int(r['count'])
                }
                comments_data.append(item)
                
                if r.get('replies'):
                    for sub in r['replies']:
                        sub_item = {
                            'ç”¨æˆ·å': sub['member']['uname'],
                            'å†…å®¹': f"[å›å¤] {sub['content']['message']}",
                            'ç‚¹èµ': int(sub['like']),
                            'æ—¶é—´': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(sub['ctime'])),
                            'å›å¤æ•°': 0
                        }
                        comments_data.append(sub_item)

            progress_bar.progress(min(page / limit_pages, 1.0))
            page += 1
            await asyncio.sleep(0.5)
            
    except Exception as e:
        st.error(f"ä¸­æ–­: {e}")
    
    return title, comments_data

# --- UI å¸ƒå±€ ---

st.title("ğŸª Bç«™è¯„è®ºæŠ“å– (æ’åº+PDFç‰ˆ)")

with st.sidebar:
    st.header("ğŸ” èº«ä»½éªŒè¯ (æ¨è)")
    st.info("ç²˜è´´ Cookie JSON")
    
    cookie_input = st.text_area(
        "Cookie æ•°æ®:", 
        height=150,
        placeholder='{"url": "...", "cookies": [...]}'
    )
    
    cred = None
    if cookie_input:
        cred, err_msg = parse_cookie_json(cookie_input)
        if cred:
            st.success("âœ… Cookie è§£ææˆåŠŸï¼")
        else:
            st.error(f"âŒ {err_msg}")
            
    st.divider()
    max_pages = st.slider("æŠ“å–é¡µæ•°", 1, 100, 5)

url_input = st.text_input("ğŸ‘‡ è§†é¢‘é“¾æ¥", placeholder="https://b23.tv/...")

# === ç¬¬ä¸€éƒ¨åˆ†ï¼šæŠ“å–é€»è¾‘ ===
if st.button("å¼€å§‹æŠ“å–", type="primary"):
    if not url_input:
        st.warning("è¯·è¾“å…¥é“¾æ¥")
    else:
        bv_id, real_url = extract_bv(url_input)
        if not bv_id:
            st.error("æ— æ³•è¯†åˆ« BV å·")
        else:
            st.success(f"æ­£åœ¨æŠ“å–: {bv_id}")
            
            try:
                loop = asyncio.get_event_loop()
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            
            # æŠ“å–æ•°æ®
            title, data = loop.run_until_complete(fetch_comments_async(bv_id, max_pages, credential=cred))
            
            if isinstance(data, str):
                st.error(data)
            elif data:
                # ã€é‡è¦ä¿®æ”¹ã€‘å°†æ•°æ®å­˜å…¥ Session Stateï¼Œè€Œä¸æ˜¯ç›´æ¥æ˜¾ç¤º
                st.session_state.comments_data = data
                st.session_state.video_title = title
                st.session_state.bv_id = bv_id
                st.rerun() # å¼ºåˆ¶åˆ·æ–°é¡µé¢ï¼Œè¿›å…¥ä¸‹æ–¹çš„æ˜¾ç¤ºé€»è¾‘
            else:
                st.warning("æœªæŠ“å–åˆ°æ•°æ®ã€‚")

# === ç¬¬äºŒéƒ¨åˆ†ï¼šæ˜¾ç¤ºä¸æ“ä½œé€»è¾‘ (åªè¦ Session State é‡Œæœ‰æ•°æ®å°±æ˜¾ç¤º) ===
if st.session_state.comments_data:
    st.divider()
    
    # ä» State ä¸­è¯»å–æ•°æ®
    title = st.session_state.video_title
    bv_id = st.session_state.bv_id
    data = st.session_state.comments_data
    
    st.subheader(f"ğŸ“„ {title}")
    
    df = pd.DataFrame(data)
    
    # å¸ƒå±€å®¹å™¨
    col1, col2 = st.columns([3, 1])
    
    with col2:
        st.markdown("### ğŸ› ï¸ æ•°æ®é€‰é¡¹")
        
        # 1. æ’åºé€‰æ‹©
        sort_order = st.radio(
            "æ’åºæ–¹å¼ (æŒ‰ç‚¹èµ)",
            ("é»˜è®¤ (æ—¶é—´)", "ç‚¹èµæ•° (é«˜åˆ°ä½)", "ç‚¹èµæ•° (ä½åˆ°é«˜)")
        )
        
        # 2. åº”ç”¨æ’åº
        if sort_order == "ç‚¹èµæ•° (é«˜åˆ°ä½)":
            df = df.sort_values(by="ç‚¹èµ", ascending=False)
        elif sort_order == "ç‚¹èµæ•° (ä½åˆ°é«˜)":
            df = df.sort_values(by="ç‚¹èµ", ascending=True)
        
        st.write(f"å…±æŠ“å– {len(df)} æ¡è¯„è®º")
        
        # 3. CSV ä¸‹è½½
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ CSV",
            data=csv,
            file_name=f"{bv_id}_comments.csv",
            mime="text/csv"
        )
        
        # 4. PDF ä¸‹è½½
        st.write("---")
        # è¿™é‡Œä½¿ç”¨åµŒå¥— Button é€»è¾‘ï¼Œå½“ç‚¹å‡»ç”Ÿæˆåï¼Œæ•°æ®ä¾ç„¶å­˜åœ¨ï¼Œæ‰€ä»¥ä¸ä¼šè·³å›é¦–é¡µ
        if st.button("ç”Ÿæˆ PDF"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆ PDF (å¯èƒ½éœ€è¦å‡ ç§’)..."):
                # ä½¿ç”¨å½“å‰æ’åºåçš„ df ç”Ÿæˆ PDF
                pdf_buffer = create_pdf(df, title)
                if pdf_buffer:
                    st.success("ç”ŸæˆæˆåŠŸï¼")
                    st.download_button(
                        label="ğŸ“¥ ç‚¹å‡»ä¸‹è½½ PDF",
                        data=pdf_buffer,
                        file_name=f"{bv_id}_comments.pdf",
                        mime="application/pdf"
                    )
                else:
                    st.error("PDF ç”Ÿæˆå¤±è´¥ã€‚")

    with col1:
        # å±•ç¤ºè¡¨æ ¼ (ä¼šå±•ç¤ºæ’åºåçš„ç»“æœ)
        st.dataframe(df, use_container_width=True, height=500)
        
    # å¦‚æœæƒ³æ¸…é™¤ç»“æœï¼Œç»™ä¸ªé‡ç½®æŒ‰é’®
    if st.button("ğŸ”„ æ¸…ç©ºç»“æœ"):
        st.session_state.comments_data = None
        st.rerun()
