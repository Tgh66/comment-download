import streamlit as st
import yt_dlp
import pandas as pd
import io
from docx import Document
from reportlab.lib import colors
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle

# --- æ ¸å¿ƒå‡½æ•°ï¼šè·å–è§†é¢‘ä¿¡æ¯ï¼ˆå«ç‚¹èµæ•°ï¼‰ ---
def get_video_metadata(urls):
    data = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    ydl_opts = {
        'quiet': True,
        'no_warnings': True,
        'extract_flat': True, # å°è¯•å¿«é€ŸæŠ“å–
    }

    for i, url in enumerate(urls):
        if not url.strip():
            continue
        
        status_text.text(f"æ­£åœ¨åˆ†æç¬¬ {i+1} ä¸ªé“¾æ¥: {url} ...")
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=False)
                
                # æå–å…³é”®ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™å¡«å…¥é»˜è®¤å€¼
                title = info.get('title', 'Unknown Title')
                like_count = info.get('like_count', 0) # å¦‚æœæ²¡æœ‰è·å–åˆ°ç‚¹èµï¼Œé»˜è®¤ä¸º0
                uploader = info.get('uploader', 'Unknown')
                view_count = info.get('view_count', 0)
                
                # å¤„ç†Noneçš„æƒ…å†µï¼ˆæœ‰äº›å¹³å°å¯èƒ½éšè—æ•°æ®ï¼‰
                if like_count is None: like_count = 0
                if view_count is None: view_count = 0

                data.append({
                    "æ ‡é¢˜": title,
                    "ç‚¹èµæ•°": like_count,
                    "æ’­æ”¾é‡": view_count,
                    "UPä¸»/ä½œè€…": uploader,
                    "é“¾æ¥": url
                })
        except Exception as e:
            st.error(f"é“¾æ¥ {url} è§£æå¤±è´¥: {e}")
        
        progress_bar.progress((i + 1) / len(urls))
    
    status_text.text("åˆ†æå®Œæˆï¼")
    progress_bar.empty()
    return pd.DataFrame(data)

# --- è¾…åŠ©å‡½æ•°ï¼šç”Ÿæˆ Word æ–‡ä»¶ ---
def generate_word(df):
    doc = Document()
    doc.add_heading('è§†é¢‘æ•°æ®ç»Ÿè®¡', 0)
    
    # æ·»åŠ è¡¨æ ¼
    t = doc.add_table(rows=1, cols=len(df.columns))
    t.style = 'Table Grid'
    
    # è¡¨å¤´
    hdr_cells = t.rows[0].cells
    for i, col_name in enumerate(df.columns):
        hdr_cells[i].text = str(col_name)
    
    # æ•°æ®è¡Œ
    for index, row in df.iterrows():
        row_cells = t.add_row().cells
        for i, value in enumerate(row):
            row_cells[i].text = str(value)
            
    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()

# --- è¾…åŠ©å‡½æ•°ï¼šç”Ÿæˆ PDF æ–‡ä»¶ ---
def generate_pdf(df):
    bio = io.BytesIO()
    doc = SimpleDocTemplate(bio, pagesize=letter)
    elements = []
    
    # è½¬æ¢æ•°æ®ä¸ºåˆ—è¡¨æ ¼å¼ [åˆ—å, è¡Œ1, è¡Œ2...]
    data = [df.columns.to_list()] + df.values.tolist()
    
    # è§£å†³ä¸­æ–‡ä¹±ç é€šå¸¸éœ€è¦æ³¨å†Œå­—ä½“ï¼Œè¿™é‡Œä¸ºäº†æ¼”ç¤ºç¨³å®šï¼ŒPDFå¯èƒ½æ— æ³•æ˜¾ç¤ºç‰¹æ®Šä¸­æ–‡å­—ç¬¦
    # å®é™…é¡¹ç›®ä¸­å»ºè®®ä½¿ç”¨ reportlab æ³¨å†Œä¸­æ–‡å­—ä½“ï¼Œæˆ–è€…ç›´æ¥æ¨èç”¨æˆ·ä¸‹è½½ Excel/Word
    
    t = Table(data)
    t.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('GRID', (0, 0), (-1, -1), 1, colors.black)
    ]))
    elements.append(t)
    doc.build(elements)
    return bio.getvalue()

# --- Streamlit ç•Œé¢å¸ƒå±€ ---
st.set_page_config(page_title="è§†é¢‘æ•°æ®æŠ“å–ä¸æ’åºå·¥å…·", layout="wide")

st.title("ğŸ“Š è§†é¢‘æ•°æ®æŠ“å– & æ™ºèƒ½æ’åºå·¥å…·")
st.markdown("è¾“å…¥è§†é¢‘é“¾æ¥ï¼Œè‡ªåŠ¨æŠ“å–ç‚¹èµæ•°å¹¶ç”ŸæˆæŠ¥è¡¨ã€‚æ”¯æŒ Bilibili, YouTube, Douyin ç­‰ã€‚")

# 1. è¾“å…¥åŒºåŸŸ
st.subheader("1. è¾“å…¥è§†é¢‘é“¾æ¥ (ä¸€è¡Œä¸€ä¸ª)")
url_input = st.text_area("ç²˜è´´é“¾æ¥åˆ°è¿™é‡Œï¼š", height=150, placeholder="https://www.bilibili.com/video/...\nhttps://www.youtube.com/watch?v=...")

if st.button("å¼€å§‹æŠ“å–æ•°æ®"):
    if not url_input.strip():
        st.warning("è¯·å…ˆè¾“å…¥é“¾æ¥ï¼")
    else:
        urls = [line.strip() for line in url_input.split('\n') if line.strip()]
        
        # è·å–æ•°æ®å¹¶å­˜å…¥ Session State é˜²æ­¢åˆ·æ–°ä¸¢å¤±
        st.session_state['df'] = get_video_metadata(urls)

# 2. æ•°æ®å¤„ç†ä¸å±•ç¤ºåŒºåŸŸ
if 'df' in st.session_state:
    df = st.session_state['df']
    
    st.divider()
    st.subheader("2. æ•°æ®æ’åºä¸é¢„è§ˆ")
    
    col1, col2 = st.columns(2)
    with col1:
        sort_by = st.selectbox("é€‰æ‹©æ’åºä¾æ®", ["ç‚¹èµæ•°", "æ’­æ”¾é‡"], index=0)
    with col2:
        sort_order = st.radio("æ’åºæ–¹å¼", ["æ­£åº (ä»ä½åˆ°é«˜)", "å€’åº (ä»é«˜åˆ°ä½)"], index=1)
    
    # æ‰§è¡Œæ’åº
    ascending = True if sort_order == "æ­£åº (ä»ä½åˆ°é«˜)" else False
    sorted_df = df.sort_values(by=sort_by, ascending=ascending)
    
    # å¢åŠ æ’ååˆ—
    sorted_df.reset_index(drop=True, inplace=True)
    sorted_df.index = sorted_df.index + 1
    st.dataframe(sorted_df, use_container_width=True)

    # 3. å¯¼å‡ºåŒºåŸŸ
    st.divider()
    st.subheader("3. å¯¼å‡ºæ•°æ®")
    
    c1, c2, c3, c4 = st.columns(4)
    
    # CSV ä¸‹è½½
    csv = sorted_df.to_csv(index=False).encode('utf-8-sig')
    c1.download_button("ä¸‹è½½ CSV", data=csv, file_name="video_stats.csv", mime="text/csv")
    
    # Excel ä¸‹è½½
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
        sorted_df.to_excel(writer, index=False, sheet_name='Sheet1')
    c2.download_button("ä¸‹è½½ Excel", data=buffer.getvalue(), file_name="video_stats.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    
    # Word ä¸‹è½½
    word_data = generate_word(sorted_df)
    c3.download_button("ä¸‹è½½ Word", data=word_data, file_name="video_stats.docx", mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document")

    # PDF ä¸‹è½½ (æ³¨ï¼šPythonç”ŸæˆPDFå¤„ç†ä¸­æ–‡è¾ƒå¤æ‚ï¼Œè¿™é‡Œä»…ä½œåŸºç¡€å®ç°)
    pdf_data = generate_pdf(sorted_df)
    c4.download_button("ä¸‹è½½ PDF", data=pdf_data, file_name="video_stats.pdf", mime="application/pdf")
